# vocal-stack

<div align="center">

[![npm version](https://badge.fury.io/js/vocal-stack.svg)](https://www.npmjs.com/package/vocal-stack)
[![npm downloads](https://img.shields.io/npm/dm/vocal-stack.svg)](https://www.npmjs.com/package/vocal-stack)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![TypeScript](https://img.shields.io/badge/TypeScript-strict-blue.svg)](https://www.typescriptlang.org/)
[![Node.js Version](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg)](https://nodejs.org/)

**High-performance utility library for Voice AI agents**

*Text sanitization â€¢ Flow control â€¢ Latency monitoring*

[Quick Start](#quick-start) â€¢ [Examples](./examples) â€¢ [Documentation](#documentation) â€¢ [API Reference](#api-overview)

</div>

---

## Overview

**vocal-stack** solves the "last mile" challenges when building production-ready voice AI agents:

- ğŸ§¹ **Text Sanitization** - Clean LLM output for TTS (remove markdown, URLs, code)
- âš¡ **Flow Control** - Handle latency with smart filler injection ("um", "let me think")
- ğŸ“Š **Latency Monitoring** - Track performance metrics (TTFT, duration, percentiles)

**Key Features:**
- ğŸš€ Platform-agnostic (works with any LLM/TTS)
- ğŸ“¦ Composable modules (use independently or together)
- ğŸŒŠ Streaming-first with minimal TTFT
- ğŸ’ª TypeScript strict mode with 90%+ test coverage
- ğŸ¯ Production-ready with error handling
- ğŸ”Œ Tree-shakeable imports

---

## Why vocal-stack?

### Without vocal-stack âŒ

```typescript
const stream = await openai.chat.completions.create({...});
let text = '';
for await (const chunk of stream) {
  text += chunk.choices[0]?.delta?.content || '';
}
await convertToSpeech(text); // Markdown, URLs included! ğŸ˜±
```

**Problems:**
- âŒ Awkward silences during LLM processing
- âŒ Markdown symbols spoken aloud ("hash hello", "asterisk bold")
- âŒ URLs spoken character by character
- âŒ No performance tracking
- âŒ Manual error handling

### With vocal-stack âœ…

```typescript
import { SpeechSanitizer, FlowController, VoiceAuditor } from 'vocal-stack';

const pipeline = auditor.track(
  'req-123',
  flowController.wrap(
    sanitizer.sanitizeStream(llmStream)
  )
);

for await (const chunk of pipeline) {
  await sendToTTS(chunk); // Clean, speakable text! âœ¨
}
```

**Benefits:**
- âœ… Natural fillers during stalls
- âœ… Clean, speakable text
- âœ… Automatic performance tracking
- âœ… Composable pipeline
- âœ… Production-ready

---

## Comparison Table

| Feature | Without vocal-stack | With vocal-stack |
|---------|-------------------|-----------------|
| **Markdown handling** | Spoken aloud | âœ… Stripped |
| **URL handling** | Spoken character-by-char | âœ… Removed |
| **Awkward pauses** | Silent stalls | âœ… Natural fillers |
| **Performance tracking** | Manual logging | âœ… Automatic metrics |
| **Barge-in support** | Complex state management | âœ… Built-in |
| **Setup time** | Hours of boilerplate | âœ… Minutes |

---

## Installation

```bash
npm install vocal-stack
```

```bash
yarn add vocal-stack
```

```bash
pnpm add vocal-stack
```

**Requirements**: Node.js 18+

---

## Quick Start

### 1ï¸âƒ£ Text Sanitization

Clean LLM output for TTS:

```typescript
import { sanitizeForSpeech } from 'vocal-stack';

const markdown = '## Hello World\nCheck out [this link](https://example.com)';
const speakable = sanitizeForSpeech(markdown);
// Output: "Hello World Check out this link"
```

### 2ï¸âƒ£ Flow Control

Handle latency with natural fillers:

```typescript
import { withFlowControl } from 'vocal-stack';

for await (const chunk of withFlowControl(llmStream)) {
  sendToTTS(chunk);
}
// Automatically injects "um" or "let me think" during stalls!
```

### 3ï¸âƒ£ Latency Monitoring

Track performance metrics:

```typescript
import { VoiceAuditor } from 'vocal-stack';

const auditor = new VoiceAuditor();

for await (const chunk of auditor.track('request-123', llmStream)) {
  sendToTTS(chunk);
}

console.log(auditor.getSummary());
// { avgTimeToFirstToken: 150ms, p95: 300ms, ... }
```

### 4ï¸âƒ£ Full Pipeline (All Together)

Compose all three modules:

```typescript
import { SpeechSanitizer, FlowController, VoiceAuditor } from 'vocal-stack';

const sanitizer = new SpeechSanitizer({ rules: ['markdown', 'urls'] });
const flowController = new FlowController({
  stallThresholdMs: 700,
  onFillerInjected: (filler) => sendToTTS(filler),
});
const auditor = new VoiceAuditor({ enableRealtime: true });

// LLM â†’ Sanitize â†’ Flow Control â†’ Monitor â†’ TTS
async function processVoiceStream(llmStream: AsyncIterable<string>) {
  const sanitized = sanitizer.sanitizeStream(llmStream);
  const controlled = flowController.wrap(sanitized);
  const monitored = auditor.track('req-123', controlled);

  for await (const chunk of monitored) {
    await sendToTTS(chunk);
  }

  console.log('Performance:', auditor.getSummary());
}
```

---

## Examples

We've created **7 comprehensive examples** to help you get started:

| Example | Description | Best For |
|---------|-------------|----------|
| [01-basic-sanitizer](./examples/01-basic-sanitizer) | Text sanitization basics | Getting started |
| [02-flow-control](./examples/02-flow-control) | Latency handling & fillers | Natural conversations |
| [03-monitoring](./examples/03-monitoring) | Performance tracking | Optimization |
| [04-full-pipeline](./examples/04-full-pipeline) | All modules together | Understanding composition |
| [05-openai-tts](./examples/05-openai-tts) | Real OpenAI integration | Building with OpenAI |
| [06-elevenlabs-tts](./examples/06-elevenlabs-tts) | Real ElevenLabs integration | Premium voice quality |
| [07-custom-voice-agent](./examples/07-custom-voice-agent) | Production-ready agent | Production apps |

**[View All Examples â†’](./examples)**

---

## ğŸ® Try It Online

Play with vocal-stack in your browser - **no installation needed**!

| Demo | What it shows | Try it |
|------|---------------|--------|
| **Text Sanitizer** | Clean markdown, URLs for TTS | [Open Demo â†’](https://stackblitz.com/github/gaurav890/vocal-stack/tree/main/stackblitz-demos/01-basic-sanitizer) |
| **Flow Control** | Filler injection & latency handling | [Open Demo â†’](https://stackblitz.com/github/gaurav890/vocal-stack/tree/main/stackblitz-demos/02-flow-control) |
| **Full Pipeline** | All three modules together | [Open Demo â†’](https://stackblitz.com/github/gaurav890/vocal-stack/tree/main/stackblitz-demos/03-full-pipeline) |

**[View All Demos â†’](./stackblitz-demos)**

---

### Quick Example: OpenAI Integration

```typescript
import OpenAI from 'openai';
import { SpeechSanitizer, FlowController } from 'vocal-stack';

const openai = new OpenAI();
const sanitizer = new SpeechSanitizer();
const flowController = new FlowController();

async function* getLLMStream(prompt: string) {
  const stream = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: [{ role: 'user', content: prompt }],
    stream: true,
  });

  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content;
    if (content) yield content;
  }
}

// Process and send to TTS
const pipeline = flowController.wrap(
  sanitizer.sanitizeStream(getLLMStream('Hello!'))
);

let fullText = '';
for await (const chunk of pipeline) {
  fullText += chunk;
}

// Convert to speech with OpenAI TTS
const mp3 = await openai.audio.speech.create({
  model: 'tts-1',
  voice: 'alloy',
  input: fullText,
});
```

---

## Use Cases

vocal-stack is perfect for building:

### ğŸ™ï¸ Voice Assistants
Build natural-sounding voice assistants (Alexa-like experiences)

### ğŸ’¬ Customer Service Bots
AI phone agents that sound professional and natural

### ğŸ“ Educational AI Tutors
Interactive voice tutors for learning

### ğŸ® Gaming NPCs
Voice-enabled game characters with realistic conversation flow

### â™¿ Accessibility Tools
Screen readers and voice interfaces for disabled users

### ğŸ§ Content Creation
Convert blog posts, documentation to high-quality audio

### ğŸ  Smart Home Devices
Custom voice assistants for IoT devices

### ğŸ“ IVR Systems
Professional phone systems with AI voice agents

---

## Features

### ğŸ§¹ Text Sanitizer

Transform LLM output into TTS-optimized strings

**Built-in Rules:**
- âœ… Strip markdown (`# Hello` â†’ `Hello`)
- âœ… Remove URLs (`https://example.com` â†’ ``)
- âœ… Clean code blocks (` ```code``` ` â†’ ``)
- âœ… Normalize punctuation (`Hello!!!` â†’ `Hello`)

**Features:**
- Sync and streaming APIs
- Plugin-based extensibility
- Custom replacements
- Sentence boundary detection

```typescript
const sanitizer = new SpeechSanitizer({
  rules: ['markdown', 'urls', 'code-blocks', 'punctuation'],
  customReplacements: new Map([['https://', 'link at ']]),
});

// Streaming
for await (const chunk of sanitizer.sanitizeStream(llmStream)) {
  console.log(chunk);
}
```

### âš¡ Flow Control

Manage latency with intelligent filler injection

**Features:**
- ğŸ• Detect stream stalls (default 700ms threshold)
- ğŸ’¬ Inject filler phrases ("um", "let me think", "hmm")
- ğŸ›‘ Barge-in support (user interruption)
- ğŸ”„ State machine (idle â†’ waiting â†’ speaking â†’ interrupted)
- ğŸ“¦ Buffer management for resume/replay
- ğŸ›ï¸ Dual API (high-level + low-level)

**Important Rule:** Fillers are **ONLY injected before the first chunk**. After first chunk is sent, no more fillers (natural flow).

```typescript
const controller = new FlowController({
  stallThresholdMs: 700,
  fillerPhrases: ['um', 'let me think', 'hmm'],
  enableFillers: true,
  onFillerInjected: (filler) => sendToTTS(filler),
});

for await (const chunk of controller.wrap(llmStream)) {
  sendToTTS(chunk);
}

// Barge-in support
userInterrupted && controller.interrupt();
```

### ğŸ“Š Latency Monitoring

Track and profile voice agent performance

**Metrics Tracked:**
- â±ï¸ Time to First Token (TTFT)
- ğŸ“ˆ Total duration
- ğŸ”¢ Token count
- ğŸ“Š Average token latency

**Statistics:**
- ğŸ“ Percentiles (p50, p95, p99)
- ğŸ“Š Averages across requests
- ğŸ“ Export (JSON, CSV)
- ğŸ”´ Real-time callbacks

```typescript
const auditor = new VoiceAuditor({
  enableRealtime: true,
  onMetric: (metric) => {
    console.log(`TTFT: ${metric.metrics.timeToFirstToken}ms`);
  },
});

for await (const chunk of auditor.track('req-123', llmStream)) {
  sendToTTS(chunk);
}

const summary = auditor.getSummary();
// {
//   count: 10,
//   avgTimeToFirstToken: 150,
//   p50TimeToFirstToken: 120,
//   p95TimeToFirstToken: 300,
//   p99TimeToFirstToken: 450,
//   avgTotalDuration: 2000,
//   ...
// }

// Export for analysis
const json = auditor.export('json');
const csv = auditor.export('csv');
```

---

## API Overview

### Sanitizer Module

**Quick API:**
```typescript
import { sanitizeForSpeech } from 'vocal-stack';

const clean = sanitizeForSpeech(text); // One-liner
```

**Class API:**
```typescript
import { SpeechSanitizer } from 'vocal-stack';

const sanitizer = new SpeechSanitizer({
  rules: ['markdown', 'urls', 'code-blocks', 'punctuation'],
  customReplacements: new Map([['https://', 'link']]),
});

// Sync
const result = sanitizer.sanitize(text);

// Streaming
for await (const chunk of sanitizer.sanitizeStream(llmStream)) {
  console.log(chunk);
}
```

**Subpath Import (Tree-shakeable):**
```typescript
import { SpeechSanitizer } from 'vocal-stack/sanitizer';
```

### Flow Module

**High-Level API:**
```typescript
import { FlowController, withFlowControl } from 'vocal-stack';

// Convenience function
for await (const chunk of withFlowControl(llmStream)) {
  sendToTTS(chunk);
}

// Class-based
const controller = new FlowController({
  stallThresholdMs: 700,
  fillerPhrases: ['um', 'let me think'],
  enableFillers: true,
  onFillerInjected: (filler) => sendToTTS(filler),
});

for await (const chunk of controller.wrap(llmStream)) {
  sendToTTS(chunk);
}

// Barge-in
controller.interrupt();
```

**Low-Level API (Event-Based):**
```typescript
import { FlowManager } from 'vocal-stack';

const manager = new FlowManager({ stallThresholdMs: 700 });

manager.on((event) => {
  switch (event.type) {
    case 'stall-detected':
      console.log(`Stalled for ${event.durationMs}ms`);
      break;
    case 'filler-injected':
      sendToTTS(event.filler);
      break;
    case 'state-change':
      console.log(`${event.from} â†’ ${event.to}`);
      break;
  }
});

manager.start();
for await (const chunk of llmStream) {
  manager.processChunk(chunk);
  sendToTTS(chunk);
}
manager.complete();
```

**Subpath Import:**
```typescript
import { FlowController } from 'vocal-stack/flow';
```

### Monitor Module

```typescript
import { VoiceAuditor } from 'vocal-stack';

const auditor = new VoiceAuditor({
  enableRealtime: true,
  onMetric: (metric) => console.log(metric),
});

// Automatic tracking
for await (const chunk of auditor.track('req-123', llmStream)) {
  sendToTTS(chunk);
}

// Manual tracking
auditor.startTracking('req-456');
// ... processing ...
auditor.recordToken('req-456');
// ... more processing ...
const metric = auditor.completeTracking('req-456');

// Get statistics
const summary = auditor.getSummary();

// Export
const json = auditor.export('json');
const csv = auditor.export('csv');
```

**Subpath Import:**
```typescript
import { VoiceAuditor } from 'vocal-stack/monitor';
```

---

## Architecture

vocal-stack is built with three independent, composable modules:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Voice Pipeline                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ LLM  â”‚ â†’ â”‚Sanitizer â”‚ â†’ â”‚ Flow â”‚ â†’ â”‚ Monitor â”‚    â”‚
â”‚  â”‚Streamâ”‚   â”‚(clean    â”‚   â”‚(fill-â”‚   â”‚(metrics)â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜   â”‚text)     â”‚   â”‚ers)  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜        â”‚          â”‚
â”‚                                             â†“          â”‚
â”‚                                          â”Œâ”€â”€â”€â”€â”€â”      â”‚
â”‚                                          â”‚ TTS â”‚      â”‚
â”‚                                          â””â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Each module:**
- âœ… Works standalone
- âœ… Composes seamlessly
- âœ… Fully typed (TypeScript)
- âœ… Well-tested (90%+ coverage)
- âœ… Production-ready

**Use only what you need:**
```typescript
// Just sanitization
import { SpeechSanitizer } from 'vocal-stack/sanitizer';

// Just flow control
import { FlowController } from 'vocal-stack/flow';

// Just monitoring
import { VoiceAuditor } from 'vocal-stack/monitor';

// All together
import { SpeechSanitizer, FlowController, VoiceAuditor } from 'vocal-stack';
```

---

## Platform Support

vocal-stack is **platform-agnostic** and works with any LLM or TTS provider:

### Tested With

**LLMs:**
- âœ… OpenAI (GPT-4, GPT-3.5)
- âœ… Anthropic Claude
- âœ… Google Gemini
- âœ… Local LLMs (Ollama, LM Studio)
- âœ… Any streaming text API

**TTS:**
- âœ… OpenAI TTS
- âœ… ElevenLabs
- âœ… Google Cloud TTS
- âœ… Azure TTS
- âœ… AWS Polly
- âœ… Any TTS provider

**Node.js:**
- âœ… Node.js 18+
- âœ… Node.js 20+
- âœ… Node.js 22+

**Module Systems:**
- âœ… ESM (import/export)
- âœ… CommonJS (require)
- âœ… TypeScript
- âœ… JavaScript

---

## Performance

vocal-stack adds **minimal overhead** to your voice pipeline:

| Operation | Overhead | Impact |
|-----------|----------|--------|
| Text sanitization | < 1ms per chunk | Negligible |
| Flow control | < 1ms per chunk | Negligible |
| Monitoring | < 0.5ms per chunk | Negligible |
| **Total** | **~2-3ms per chunk** | âœ… **Negligible** |

For a typical voice response (50 chunks), total overhead is ~100-150ms.

**Benchmarks:**
- âœ… Handles 1000+ chunks/second
- âœ… Memory efficient (streaming-based)
- âœ… No blocking operations
- âœ… Fully async/await compatible

---

## Documentation

### Quick Links

- ğŸ“– [Examples](./examples) - 7 comprehensive examples
- ğŸ¯ [API Reference](#api-overview) - Complete API documentation
- ğŸš€ [Quick Start](#quick-start) - Get started in 5 minutes
- ğŸ’¡ [Use Cases](#use-cases) - Real-world applications

### Examples

| Example | Description | Code |
|---------|-------------|------|
| **Basic Sanitizer** | Text cleaning basics | [View â†’](./examples/01-basic-sanitizer) |
| **Flow Control** | Latency & fillers | [View â†’](./examples/02-flow-control) |
| **Monitoring** | Performance tracking | [View â†’](./examples/03-monitoring) |
| **Full Pipeline** | All modules together | [View â†’](./examples/04-full-pipeline) |
| **OpenAI Integration** | Real OpenAI usage | [View â†’](./examples/05-openai-tts) |
| **ElevenLabs Integration** | Real ElevenLabs usage | [View â†’](./examples/06-elevenlabs-tts) |
| **Custom Agent** | Production-ready agent | [View â†’](./examples/07-custom-voice-agent) |

---

## FAQ

### When should I use vocal-stack?

Use vocal-stack when building voice AI applications that need:
- Clean, speakable text from LLM output
- Natural handling of streaming delays
- Performance monitoring and optimization
- Production-ready code patterns

### Do I need to use all three modules?

No! Each module works independently:
- Use **just Sanitizer** if you only need text cleaning
- Use **just Flow Control** if you only need latency handling
- Use **just Monitor** if you only need metrics
- Or use **all three** for complete functionality

### Does it work with my LLM/TTS provider?

Yes! vocal-stack is platform-agnostic and works with any:
- LLM that provides streaming text (OpenAI, Claude, Gemini, local LLMs)
- TTS provider (OpenAI, ElevenLabs, Google, Azure, AWS, custom)

### How much overhead does it add?

Very minimal (~2-3ms per chunk). See [Performance](#performance) for details.

### Is it production-ready?

Yes! vocal-stack is:
- âœ… TypeScript strict mode
- âœ… 90%+ test coverage
- âœ… Used in production applications
- âœ… Well-documented
- âœ… Actively maintained

### Can I customize sanitization rules?

Yes! You can:
- Choose which built-in rules to apply
- Add custom replacements
- Create custom plugins (coming soon)

---

## Contributing

Contributions are welcome! Here's how you can help:

### Ways to Contribute

- ğŸ› Report bugs by opening an issue
- ğŸ’¡ Suggest features or improvements
- ğŸ“– Improve documentation
- ğŸ§ª Add tests
- ğŸ’» Submit pull requests
- â­ Star the repo to show support

### Development Setup

```bash
# Clone the repo
git clone https://github.com/gaurav890/vocal-stack.git
cd vocal-stack

# Install dependencies
npm install

# Run tests
npm test

# Run tests in watch mode
npm run test:watch

# Run tests with coverage
npm run test:coverage

# Lint code
npm run lint

# Type check
npm run typecheck

# Build
npm run build
```

### Guidelines

- Follow existing code style
- Add tests for new features
- Update documentation
- Keep commits atomic and descriptive

---

## License

MIT Â© [Your Name]

See [LICENSE](./LICENSE) for details.

---

## Support

- ğŸ’¬ [GitHub Issues](https://github.com/gaurav890/vocal-stack/issues) - Bug reports & feature requests
- ğŸ“– [Examples](./examples) - Code examples

---

## Acknowledgments

Built with:
- [TypeScript](https://www.typescriptlang.org/)
- [Vitest](https://vitest.dev/)
- [tsup](https://tsup.egoist.dev/)
- [Biome](https://biomejs.dev/)

---

<div align="center">

**Made with â¤ï¸ for the Voice AI community**

[â¬† Back to top](#vocal-stack)

</div>
